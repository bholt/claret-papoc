---
title: 'Claret: Using Data Types for Highly Concurrent Distributed Transactions'
documentclass:
  name: sigplanconf
  options: 10pt

author:
  - {family: Holt,  given: Brandon, affiliation: 1, email: bholt}
  - {family: Zhang, given: Irene,   affiliation: 1, email: iyzhang}
  - {family: Ports, given: Dan,     affiliation: 1, email: drkp}
  - {family: Oskin, given: Mark,    affiliation: 1, email: oskin}
  - {family: Ceze,  given: Luis,    affiliation: 1, email: luisceze}

organization:
  - {id: 1, name: University of Washington}

conference:
  name: PaPoC'15
  location: 'April 21, 2015, Bordeaux, France'
  year: 2015
  copyrightdata: 978-1-4503-3238-5/15/04
 
exclusivelicense: true
doi: 2745947.2745951

layout: sigplanconf
bibliography: biblio.bib
output:
  pdf_document:
    fig_caption: yes

abstract: |
  Out of the many NoSQL databases in use today, some that provide simple data structures for records, such as Redis and MongoDB, are now becoming popular. Building applications out of these complex data types provides a way to communicate intent to the database system without sacrificing flexibility or committing to a fixed schema. Currently this capability is leveraged in limited ways, such as to ensure related values are co-located, or for atomic updates. There are many ways data types can be used to make databases more efficient that are not yet being exploited.

  We explore several ways of leveraging abstract data type (ADT) semantics in databases, focusing primarily on commutativity. Using a Twitter clone as a case study, we show that using commutativity can reduce transaction abort rates for high-contention, update-heavy workloads that arise in real social networks. We conclude that ADTs are a good abstraction for database records, providing a safe and expressive programming model with ample opportunities for optimization, making databases more safe and scalable.
---
```{r setup, include=FALSE}
opts_chunk$set(dev='pdf', echo=F, message=F, warning=F, error=F, fig.width=3.6, fig.height=3)
```

# Introduction

The move to non-relational (NoSQL) databases was motivated by a desire for scalability and flexibility. People found that by giving up strong consistency, they could better scale services to millions or billions of users while meeting tight performance goals.
Because of inherent uncertainty in timing and connectivity, in many cases users are likely to accept minor inconsistencies such as two tweets being out of temporal order or needing to retry an action. In such cases, relaxed consistency feels like a natural solution, but it leaves much to chance: there is likely no guarantee that more significant inconsistencies are impossible.
When consistency is critical, developers can enforce stronger guarantees manually, or use serializable transactions in systems like Google's Spanner [@Spanner], but this leaves them with two extremes with a significant performance gap.
If certain parts of an application can tolerate imprecision, why not capture those properties in the programming model? Is there a way programmers can express the semantics they desire succinctly and precisely, helping the database optimize performance and scalability, without sacrificing flexibility?

We propose abstract data types (ADTs) as the solution. Rather than limiting the records in databases to primitive types like strings or integers, raising them to more complex data types provides a richer interface, exposing ample opportunities for optimization to the database and a precise mechanism to express the intentions of programmers. In this work we explore several ways of leveraging commutativity and data types to improve database performance and allow programmers to make tradeoffs between performance and precision, starting by demonstrating one way of using commutativity to reduce transaction aborts.

# Commutativity {#comm}

Commutativity is well known, especially in distributed systems, for enabling important optimizations. Since the 80s, commutativity has been exploited by database systems designers [@Weihl:1988;@Fekete:90] within the safe confines of relational models, where complete control of the data structures allows systems to determine when transactions may conflict. Recently, commutativity has seen a resurgence in systems without a predefined data model, such as NoSQL databases and transactional memory.
Eventually consistent databases use commutativity for convergence in work such as RedBlue consistency [@Li:OSDI12] and conflict-free replicated data types (CRDTs) [@Shapiro:SSS11]. Other systems specialize for commutative operations to improve transaction processing, such as Lynx [@Zhang:SOSP13] for tracking serializability, Doppel [@Narula:OSDI14] for executing operations in parallel on highly contended records, and HyFlow [@Kim:EuroPar13] for reordering operations in the context of distributed transactional memory. We propose unifying and generalizing these under the abstraction afforded by ADTs.

\begin{table}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lll}
\textbf{method:} & \textbf{commutes with:} & \textbf{when:} \\
\hline
\texttt{add(x): void} & \texttt{add(y)} & $\forall x, y$ \\
\texttt{remove(x): void} & \texttt{remove(y)} & $\forall x, y$ \\
    & \texttt{add(y)} & $x \ne y$ \\
\texttt{size(): int} & \texttt{add(x)} & $x \in Set$ \\
    & \texttt{remove(x)} & $x \notin Set$ \\
\texttt{contains(x): bool} & \texttt{add(y)} & $x \ne y \lor y \in Set$ \\
    & \texttt{remove(y)} & $x \ne y \lor y \notin Set$ \\
    & \texttt{size()} & $\forall x$ \\
    \hline
\end{tabular}
\caption{\label{spec} Commutativity Specification for Set.}}
\end{table}

Though *commutativity* is often discussed in terms of an operation commuting with all other operations, it is actually more nuanced. If a pair of operations commute, then executing them in either order will produce the same result. Using the definitions from [@Kulkarni:PLDI11], whether or not a pair of method invocations commute is a function of the methods, their arguments, their return values, and the *abstract* state of their target. We call the full set of commutativity rules for an ADT its *commutativity specification.* An example specification for a *Set* is shown in \autoref{spec}. There are actually many valid specifications which expose less than the maximum commutativity, but may be cheaper to implement.

**Transaction boosting.** If two operations on the same record in two different transactions commute, then the transactions can safely execute concurrently, even though they both update the record. This technique is known as *transactional boosting* [@Herlihy:PPoPP08]. This straightforward use of commutativity was shown to significantly improve abort rates in software transactional memory. In \autoref{eval}, we show how we applied it to distributed transactions.

**Combining.** Associativity, often paired with commutativity, allows some concurrent operations to be *combined* before being applied to the data structure itself. *Combining* [@flatCombining;@yew:combining-trees;@funnels] can drastically reduce contention on shared data structures. This technique could be applied to hot records, similar to *splitting* in Doppel [@Narula:OSDI14], to avoid bottlenecking on a single shard.

# Data type selection

Choosing an ADT with semantics specialized for a particular use case gives the system the best chance of scaling performance.
For example, rather than using a counter, which must return the next number in the sequence (which is difficult to scale, as users of TPC-C [@TPCC] know well)
For example, an application needing to generate unique IDs should not use a counter, which must return the next number in the sequence, because this is very difficult to scale (as users of TPC-C [@TPCC], which explicitly requires this, know well). Instead, a `UniqueID` type succinctly expresses that non-sequential IDs are okay, which can be implemented very efficiently. By allowing approximations or non-determinism, performance may be further improved.

**Probabilistic data types** such as *bloom filters* [@bloom], *hyperloglogs* [@hyperloglog], and *count-min sketches* [@countminsketch] trade off accuracy (within fixed bounds) for better performance or storage. Twitter's streaming analytics system [@summingbird] and many machine learning algorithms leverage these to handle high data volume, and we expect similar benefit.

**Conflict-free replicated data types (CRDTs)**, which were invented for eventual consistency, can actually be fit into our model as well, as a new kind of data type. Copies of a record could exist in different shards, asynchronously updating each other. By defining the same kind of *merge* function as traditional CRDTs, these copies could ensure they all converge to the same state. Clients may find them more difficult to reason about but might make that tradeoff in parts of the application where it otherwise cannot scale.

# Evaluation {#eval}
To demonstrate the efficacy of leveraging commutative operations in transactions, we built a simple prototype key-value store, modeled after Redis, that supports complex data types for records, each with their own set of operations. Our experiments were carried out with 4 shards on 4 local nodes, each with 8-core 2GHz Xeon E5335 processors and standard ethernet connecting them.

## Transaction protocol

The transaction protocol employs standard two-phase commit and two-phase locking with retries to ensure isolation, atomicity. We implement a number of standard optimizations, such as delaying acquiring locks for operations that don't return a value to the *prepare* step so that locks are held for as short a time as possible. However, there is one step that is non-standard in order to support complex data types where rolling back state changes would be non-trivial.

To support transactions with arbitrary data structure operations, each operation is split into two steps: *stage* and *apply*. During transaction execution, each operation's *stage* method attempts to acquire the necessary lock and may return a value *as if the operation has completed* (e.g. an "increment" speculatively returns the incremented value). When the transaction is prepared to commit, *apply* is called on each staged operation to actually mutate the underlying data structure. This allows operations to easily be un-staged if the transaction fails to acquire all the necessary locks, without requiring rollbacks.

Commutativity comes into play in the locking scheme. Using the algorithms from [@Kulkarni:PLDI11] and our commutativity specifications, we design an abstract lock for each record type. Our `SortedSet`, for instance, has an `add` mode which allows all insertion operations to commute, but disallows operations like `contains` or `size`.
As a baseline, we implement a standard reader/writer locking scheme that allows all read-only operations to execute concurrently, but enforces that only one transaction may modify a record at a time.

## Microbenchmark: Set operations

```{r stress, include=F, fig.width=2.8, fig.height=3.1}
d <- data(db("
    select * from tapir where 
    total_time is not null
    and name like 'stress-v0.14%'
    ", factors=c('nshards', 'nclients'), numeric=c('total_time', 'txn_count')))
d$opmix <- factor(revalue(d$mix, c(
    'mostly_update'='35% read\n65% update',
    'update_heavy'='50% read\n50% update',
    'read_heavy'='90% read\n10% update'
)))
d$dist <- factor(revalue(d$alpha, c('0.6'='Zipf: 0.6', '-1'='Uniform')))
d.u <- subset(d, nshards == 4 & nkeys == 10000 
    & (alpha == '0.6' | alpha == '-1') 
    & grepl('update_heavy|read_heavy', mix)
)
ggplot(d.u, aes(x=nclients, y=throughput/1000,
        group=cc, fill=cc, color=cc, linetype=cc))+
    stat_summary(fun.y=max, geom="line", size=0.4)+
    xlab('Concurrent clients')+ylab('Throughput (k/sec)')+
    expand_limits(y=0)+
    facet_grid(dist~opmix)+
    theme_mine+
    theme(legend.position=c(0.5,-0.22), plot.margin=unit(c(.5,.5,8,.5),'mm'), legend.direction='horizontal', legend.title.align=1)+
    cc_scales(title='Concurrency\ncontrol:')
```
\begin{figure}[t]
\centering
\includegraphics{figure/stress-1.pdf}
\caption{Throughput of raw Set operations.\label{stress_tput}}
\end{figure}

We first evaluate performance with a simple workload consisting of a raw mix of `Set` operations randomly distributed over 10,000 keys. We use both a uniform random distribution as well as a skewed Zipfian distribution with a coefficient of 0.6. In \autoref{stress_tput}, we see that commutative transactions perform strictly better, showing the most pronounced benefit over the more update-heavy, skewed workload.

## Case study: Retwis
To understand performance on a typical web workload, we use *Retwis*, a simplified Twitter clone designed originally for Redis [@redis]. Data structures such as sets are used track each user's followers and posts and keep a materialized up-to-date timeline for each user (represented as a sorted set). On top of Retwis's basic functionality, we added a "repost" action that behaves like Twitter's "retweet".

```{r}
df <- subset(db("
    select * from tapir where stat_following_counts is not null
    and name like '%v0.14%'
"),
  nclients == 32
  & initusers == 4096
)
df$grp <- with(df, sprintf("%s\n%s\nmix:%s/%s,\n%s", name, ccmode, mix, alpha, gen))

histogram.facets <- function(df, measure, grp) {
  d <- data.frame(x=c(),y=c(),version=c())
  for (i in 1:nrow(df)) {
    d <- rbind(d, df.histogram(df[i,measure], df[i,grp]))
  }
  return(d)
}
```

```{r followers, include=F, fig.width=2.5, fig.height=2.3}
d.follow <- histogram.facets(subset(df,
    initusers == 4096 & mix == 'geom_repost'
), 'stat_follower_counts', 'grp')
ggplot(d.follow, aes(x=x, weight=y))+
    stat_ecdf(color=c.blue)+
    xlab('# followers / user (log scale)')+ylab('CDF (log scale)')+
    scale_x_log10(breaks=c(1,10,100,1000))+scale_y_log10(breaks=c(0.1,0.5,1.0))+
    theme_mine
```
\begin{figure}[t]\centering
\includegraphics{figure/followers-1.pdf}
\caption{CDF of the number of followers for users generated by the
Kronecker synthetic graph generator, matching the power-law degree
distribution of natural graphs.\label{followers}}
\end{figure}


```{r reposts, include=F, fig.width=2.5, fig.height=2.3}
d.repost <- histogram.facets(
    subset(df, initusers == 4096 & mix == 'geom_repost')
, 'stat_repost_counts', 'grp')
ggplot(d.repost, aes(x=x, weight=y))+
    stat_ecdf(color=c.blue)+
    xlab('# reposts')+ylab('count')+
    scale_x_log10(breaks=c(1,10,100,1000))+
    scale_y_log10(breaks=c(0.1,0.2,0.4,0.6,0.8,1.0))+
    xlab('# reposts (log scale)')+ylab('CDF (log scale)')+
    theme_mine
```
\begin{figure}[t]\centering
\includegraphics{figure/reposts-1.pdf}
\caption{CDF of the number of times a post is reposted, matching traces
from real workloads. Due to the power-law graph structure, if users tend
to reposts popular recent posts on their timeline, it results in another
power-law distribution. Note that that some posts are reposted to over a
quarter of the graph (4000 total users).\label{reposts}}
\end{figure}

We simulate a realistic workload using a synthetic graph with power-law degree distribution and clients that randomly select between Retwis transactions including "add follower", "new post", and "repost", executing them as fast as they can.

Rather than simply approximating the skew in real-world workloads with a Zipfian distribution as many other systems do, we simulate the behavior of social networks with a realistic synthetic graph and a simple model of user behavior for posting and reposting.

For our synthetic graph, we use the Kronecker graph generator from the Graph 500 benchmark [@graph500]. This generator is designed to result in graphs with the same power-law degree distribution found in natural graphs. \autoref{followers} shows the cumulative distribution function (CDF) of the number of followers per user for the synthetic graph of approximately 4000 users, with an average number of followers of 16 (scale 12 with edgefactor of 16 in Graph500's terms). Most users should have relatively few followers; we see that roughly 50% have fewer than 100 followers, while a very small number of users have over 1000 followers.

We use a simple model of user behavior to determine when and which posts to repost. Each time we load the most recent posts in a timeline for a random user (uniformly selected), they are sorted by the number of times they have already been reposted, and a discrete geometric distribution, skewed toward 0, is used to select the number of these to repost. This results in the "viral" propagation effect that is observed in real social networks. \autoref{reposts} shows the distribution of the number of times a post was reposted, which is again a power-law distribution. Note that a small number of posts are reposted so much that they end up on over a quarter of users' timelines.

```{r throughput, include=F, fig.width=2.5, fig.height=2.8}
d <- data(db("
    select * from tapir where 
    generator_time is not null and total_time is not null
    and name like 'claret-v0.14%'
  ",
    factors=c('nshards', 'nclients'),
    numeric=c('total_time', 'txn_count')
))
d.u <- subset(d, nshards == 4 & initusers == 4096 & nclients != 96 & nclients != 128
                & grepl('geom_repost|read_heavy', mix))
ggplot(d.u, aes(x=nclients, y=throughput/1000, 
        group=cc, fill=cc, color=cc, linetype=cc))+
    stat_summary(fun.y=mean, geom="line", size=0.4)+
    xlab('Concurrent clients')+ylab('Throughput (k trans. / sec)')+
    expand_limits(y=0)+
    facet_wrap(~workload)+
    theme_mine+
    theme(legend.position=c(0.5,-0.25), plot.margin=unit(c(.5,.5,8,.5),'mm'), legend.direction='horizontal', legend.title.align=1)+
    cc_scales(title='Concurrency\ncontrol:')
```
\begin{figure}[t]
\centering
\includegraphics{figure/throughput-1.pdf}
\caption{Throughput of social network workload (Retwis) with 4000 users.
Leveraging commutativity prevents performance from falling over even
when posts spread virally (repost-heavy).\label{tput}}
\end{figure}

\autoref{tput} shows the results of this simulation. When most of the traffic is content consumption (reading timelines), both systems perform well enough. However, when we simulate a workload where clients repost popular posts from their timelines, we see a viral propagation effect, where a large fraction of the users get and share a post. As Twitter came to a standstill when Ellen DeGeneres's Oscar selfie set a retweeting record [@ellenselfie], so too does our baseline fall over. But with commutativity, performance continues to scale even under this highly contentious load.
